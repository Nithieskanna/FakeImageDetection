{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a5f62-49e8-4852-8fd6-fc1fa00104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Librabries\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import tensorflow.compat.v2 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from lime import submodular_pick\n",
    "import skimage.io \n",
    "import skimage.segmentation\n",
    "\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8809a-3bd7-49ae-af0b-5049de8c29b3",
   "metadata": {},
   "source": [
    "### TRAINING AND TESTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a196c5-71bb-4360-87b2-73577792d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Dataset\\\\Train'\n",
    "val_path = 'Dataset\\\\Val'\n",
    "\n",
    "# create the data generators\n",
    "train_datagen = ImageDataGenerator( rescale=1./255, \n",
    "                             rotation_range=20,  \n",
    "                             zoom_range=0.2,   \n",
    "                             width_shift_range=0.1,  \n",
    "                             height_shift_range=0.1, \n",
    "                             brightness_range=[0.2, 0.8],\n",
    "                             shear_range=0.2,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=False)    \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=['Real', 'Fake_Photoshop', 'Fake_Deepfake', 'Fake_Gan'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path ,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=['Real', 'Fake_Photoshop', 'Fake_Deepfake', 'Fake_Gan'],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cd09b-385b-4fbd-af99-47bc805f0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XceptionNet model\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add output layers\n",
    "image_type = Dense(4, activation='softmax', name='type')(x)\n",
    "\n",
    "# Create the custom model\n",
    "model = Model(inputs=base_model.input, outputs=image_type)\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a52f32-843b-430e-b0fe-434f5b073eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'D:\\\\Nithies_FYP\\\\Checkpoints'\n",
    "custom_callbacks = [EarlyStopping(monitor='loss', mode='min', patience=3, verbose=1),\n",
    "                    ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.00001),\n",
    "                    ModelCheckpoint(filepath=os.path.join(checkpoint_path, 'final_model_checkpoint.h5'),\n",
    "                                                          monitor='loss', \n",
    "                                                          mode='min', \n",
    "                                                          verbose=1,\n",
    "                                                          save_best_only=True)\n",
    "                    ]\n",
    "\n",
    "# train the model using the fit_generator method\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=custom_callbacks,\n",
    "        validation_steps=len(val_generator))\n",
    "\n",
    "#Saving the History\n",
    "with open('D:\\\\Nithies_FYP\\\\Checkpoints\\\\trainHistory', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "    \n",
    "# #Loading the history    \n",
    "# with open('/trainHistoryDict', \"rb\") as file_pi:\n",
    "#     history = pickle.load(file_pi)\n",
    "    \n",
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cae244-5180-458f-9ef3-ac860d4f2df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\\\Nithies_FYP\\\\Models\\\\final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7699c01-cb94-4884-9d1c-087c67b4c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting Graphs\n",
    "\n",
    "#Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d5de0-351f-4532-b7f0-894b02829c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "test_path = 'D:\\\\FYP PROJECT\\\\Preprocess3\\\\Test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path ,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=['Real', 'Fake_Photoshop', 'Fake_Deepfake', 'Fake_Gan'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e9f6f-c1d6-4312-8e09-f9bca30a282e",
   "metadata": {},
   "source": [
    "### Loading the Prototype and Implementing XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c002b-d7f1-4339-af60-e926f17c7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Model\n",
    "new_model = tf.keras.models.load_model('Models\\\\final_model.h5')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873a312-1724-400f-93cf-d1edc69bb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating XAI instance\n",
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813cd8c-d931-4546-a39e-75b43c6fc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Readind the Image\n",
    "img = plt.imread(\"D:\\\\root\\\\pics\\\\Friends\\\\Snapchat-2053075564.jpg\")\n",
    "\n",
    "print(\"image shape : \", img.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3137d-b9fd-4b21-b995-813b596dada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    x = plt.axis('off')\n",
    "    x = plt.imshow(image)\n",
    "    x = plt.show()\n",
    "    return x\n",
    "\n",
    "def preprocess(img):\n",
    "    if img.shape[-1] == 4:\n",
    "        # Convert the image from RGBA to RGB\n",
    "        img = np.array(img)\n",
    "        img = img[:, :, :3]\n",
    "    img = cv2.resize(img, (256,256)) # Resize the image to match the input size of the model\n",
    "    img = img.astype('float32') / 255.0 # Normalize the image\n",
    "    # img = np.expand_dims(img, axis=0) # Add batch dimension\n",
    "    img = img.reshape((-1,) + img.shape)\n",
    "    print(\"Done...\")\n",
    "    return img\n",
    "    \n",
    "test_image = preprocess(img)\n",
    "\n",
    "print(\"image shape : \", test_image.shape)\n",
    "image = plot_image(test_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed16092-f8f3-468a-b3fc-028c5a9db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = new_model.predict(test_image)\n",
    "\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "print(\"Prediction Class : \",predicted_class)\n",
    "# Print the prediction result\n",
    "if predicted_class == 0:\n",
    "    print('Real Image')\n",
    "elif predicted_class == 1:\n",
    "    print('Photoshopped Image')\n",
    "elif predicted_class == 2:\n",
    "    print('Deepfake Image')\n",
    "elif predicted_class == 3:\n",
    "    print('GAN-generated Image')\n",
    "else:\n",
    "    print('Unknown')\n",
    "\n",
    "print(prediction)\n",
    "print(prediction.size)\n",
    "print(\"Prediction Scores\")\n",
    "type = ['Real', 'Photoshop', 'Deepfake', 'Gan']\n",
    "count=0\n",
    "for value in prediction:\n",
    "    for val in value:\n",
    "        percentage = float(val) * 100\n",
    "        formatted_percentage = \"{:.4f}%\".format(percentage)\n",
    "        print(type[count] , \" - \" ,formatted_percentage )\n",
    "        count = count +1\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362d4d2-9da1-4711-bc40-8696e624c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(test_image[0],  new_model.predict, top_labels=4, hide_color=0, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e753f7e-73a9-4103-80fa-6da2abacb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def explanation_heatmap(exp, exp_class):\n",
    "    # '''\n",
    "    # Using heat-map to highlight the importance of each super-pixel for the model prediction\n",
    "    # '''\n",
    "    dict_heatmap = dict(exp.local_exp[exp_class])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(exp.segments) \n",
    "    \n",
    "    plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n",
    "    plt.axis('off')\n",
    "    #Saving the figure\n",
    "    h_img = plt.savefig(\"Models\\\\prediction_heatmap.jpg\", format='png')\n",
    "    plt.show()\n",
    "    return h_img\n",
    "\n",
    "\n",
    "\n",
    "def generate_prediction_sample(exp, exp_class, show_positive, hide_background, filename):\n",
    "    image, mask = exp.get_image_and_mask(exp_class, \n",
    "                                         positive_only=show_positive, \n",
    "                                         num_features=10, \n",
    "                                         hide_rest=hide_background,\n",
    "                                        )\n",
    "\n",
    "    # x = plot_image(mark_boundaries(image, mask))\n",
    "    plt.imshow(mark_boundaries(image, mask, outline_color=(0, 1, 0)))\n",
    "    plt.axis('off')\n",
    "    y = plt.savefig(\"Models\\\\prediction_highlight.jpg\", format='png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return y\n",
    "\n",
    "pred_high = generate_prediction_sample(exp, exp.top_labels[0], True, False, \"prediction_highlight\")\n",
    "\n",
    "heatmap = explanation_heatmap(exp, exp.top_labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
